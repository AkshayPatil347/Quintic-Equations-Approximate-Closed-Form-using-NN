{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074b67a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Deeper NN having 7M Parameters and dataset size as 1.6M Datapairs of input coefficients varying from -5 to 5 with integer spacing and 5 roots (Real and Imaginary separated so 10 roots)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "file_path = r\"C:\\Users\\Akshay Patil\\Desktop\\Roots\\R.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Dataset columns: {df.columns.tolist()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Extract input features (polynomial coefficients a, b, c, d, e, f)\n",
    "input_cols = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "X = df[input_cols].values\n",
    "\n",
    "# Helper function to safely extract complex parts\n",
    "def extract_complex_parts(complex_value):\n",
    "    \"\"\"\n",
    "    Extract real and imaginary parts from complex number or string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(complex_value, str):\n",
    "            # Handle string representation of complex numbers\n",
    "            complex_value = complex_value.strip()\n",
    "            complex_num = complex(complex_value)\n",
    "        elif isinstance(complex_value, (int, float)):\n",
    "            complex_num = complex(complex_value)\n",
    "        else:\n",
    "            complex_num = complex(complex_value)\n",
    "        \n",
    "        return np.real(complex_num), np.imag(complex_num)\n",
    "    except (ValueError, TypeError):\n",
    "        print(f\"Warning: Could not parse complex number: {complex_value}\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "# Extract output features (roots with real and imaginary parts)\n",
    "# # Method 1: If roots are stored as separate real/imaginary columns\n",
    "root_cols = []\n",
    "# for i in range(1, 6):  # 5 roots\n",
    "#     for part in ['real', 'imag']:\n",
    "#         col_name = f'root_{i}_{part}'\n",
    "#         if col_name in df.columns:\n",
    "#             root_cols.append(col_name)\n",
    "\n",
    "# Extract outputs based on column structure\n",
    "if len(root_cols) == 10:\n",
    "    y = df[root_cols].values\n",
    "    print(\"Using separate real/imaginary columns\")\n",
    "else:\n",
    "    # Method 2: If roots are stored as complex numbers\n",
    "    print(\"Processing complex number columns\")\n",
    "    y = np.zeros((len(df), 10))\n",
    "    \n",
    "    for i in range(5):\n",
    "        root_col = f'root_{i+1}'\n",
    "        if root_col in df.columns:\n",
    "            # Process each complex value in the column\n",
    "            for j, complex_value in enumerate(df[root_col].values):\n",
    "                real_part, imag_part = extract_complex_parts(complex_value)\n",
    "                y[j, i] = real_part      # Real parts (columns 0-4)\n",
    "                y[j, i+5] = imag_part    # Imaginary parts (columns 5-9)\n",
    "\n",
    "print(f\"Input shape: {X.shape}\")\n",
    "print(f\"Output shape: {y.shape}\")\n",
    "\n",
    "# Check for any NaN or infinite values\n",
    "print(f\"NaN values in X: {np.isnan(X).sum()}\")\n",
    "print(f\"NaN values in y: {np.isnan(y).sum()}\")\n",
    "print(f\"Infinite values in X: {np.isinf(X).sum()}\")\n",
    "print(f\"Infinite values in y: {np.isinf(y).sum()}\")\n",
    "\n",
    "# Remove any rows with NaN or infinite values\n",
    "valid_indices = ~(np.isnan(X).any(axis=1) | np.isnan(y).any(axis=1) | \n",
    "                  np.isinf(X).any(axis=1) | np.isinf(y).any(axis=1))\n",
    "X = X[valid_indices]\n",
    "y = y[valid_indices]\n",
    "\n",
    "print(f\"After cleaning - X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "# Split the data into train, validation, and test sets (60%, 20%, 20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Standardize the features\n",
    "# scaler_X = StandardScaler()\n",
    "# scaler_y = StandardScaler()\n",
    "\n",
    "# X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "# X_val_scaled = scaler_X.transform(X_val)\n",
    "# X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "# y_val_scaled = scaler_y.transform(y_val)\n",
    "# y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "print(\"Data preprocessing completed successfully!\")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Input layer + First hidden layer\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(6,), name='hidden_layer_1'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Layer 2\n",
    "    keras.layers.Dense(768, activation='relu', name='hidden_layer_2'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 3\n",
    "    keras.layers.Dense(1024, activation='relu', name='hidden_layer_3'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 4\n",
    "    keras.layers.Dense(1024, activation='relu', name='hidden_layer_4'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 5\n",
    "    keras.layers.Dense(1024, activation='relu', name='hidden_layer_5'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 6\n",
    "    keras.layers.Dense(768, activation='relu', name='hidden_layer_6'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 7\n",
    "    keras.layers.Dense(768, activation='relu', name='hidden_layer_7'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 8\n",
    "    keras.layers.Dense(768, activation='relu', name='hidden_layer_8'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    # Layer 9\n",
    "    keras.layers.Dense(512, activation='relu', name='hidden_layer_9'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 10\n",
    "    keras.layers.Dense(512, activation='relu', name='hidden_layer_10'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 11\n",
    "    keras.layers.Dense(512, activation='relu', name='hidden_layer_11'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 12\n",
    "    keras.layers.Dense(384, activation='relu', name='hidden_layer_12'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 13\n",
    "    keras.layers.Dense(384, activation='relu', name='hidden_layer_13'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 14\n",
    "    keras.layers.Dense(384, activation='relu', name='hidden_layer_14'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 15\n",
    "    keras.layers.Dense(256, activation='relu', name='hidden_layer_15'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 16\n",
    "    keras.layers.Dense(256, activation='relu', name='hidden_layer_16'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 17\n",
    "    keras.layers.Dense(256, activation='relu', name='hidden_layer_17'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 18\n",
    "    keras.layers.Dense(128, activation='relu', name='hidden_layer_18'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Layer 19\n",
    "    keras.layers.Dense(128, activation='relu', name='hidden_layer_19'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    # Layer 20\n",
    "    keras.layers.Dense(64, activation='relu', name='hidden_layer_20'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    # Output layer (10 outputs internally: 5 real parts + 5 imaginary parts)\n",
    "    keras.layers.Dense(10, activation='linear', name='output_layer')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks for training\n",
    "callbacks = [\n",
    "    # keras.callbacks.EarlyStopping(\n",
    "    #     monitor='val_loss',\n",
    "    #     patience=5,\n",
    "    #     restore_best_weights=True,\n",
    "    #     verbose=1\n",
    "    # ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=7,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'best_polynomial_roots_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=10000,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Load the best model and evaluate\n",
    "model = keras.models.load_model('best_polynomial_roots_model.keras')\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss (MSE): {test_loss:.6f}\")\n",
    "print(f\"Test MAE: {test_mae:.6f}\")\n",
    "\n",
    "# Create prediction function\n",
    "def predict_polynomial_roots(coefficients):\n",
    "    \"\"\"\n",
    "    Predict roots for a polynomial given coefficients [a,b,c,d,e,f]\n",
    "    where polynomial is: a*x^5 + b*x^4 + c*x^3 + d*x^2 + e*x + f = 0\n",
    "    \"\"\"\n",
    "    # Ensure input is numpy array\n",
    "    coeffs = np.array(coefficients).reshape(1, -1)\n",
    "    \n",
    "    # Scale the input\n",
    "    # coeffs_scaled = scaler_X.transform(coeffs)\n",
    "    \n",
    "    # Predict\n",
    "    prediction_scaled = model.predict(coeffs, verbose=0)\n",
    "    \n",
    "    # Inverse scale the output\n",
    "    # prediction = scaler_y.inverse_transform(prediction_scaled)\n",
    "    \n",
    "    # Reshape to get real and imaginary parts\n",
    "    real_parts = prediction_scaled[0][:5]\n",
    "    imag_parts = prediction_scaled[0][5:]\n",
    "    \n",
    "    # Combine into complex roots\n",
    "    roots = real_parts + 1j * imag_parts\n",
    "    \n",
    "    return roots, real_parts, imag_parts\n",
    "\n",
    "# Test the prediction function\n",
    "sample_coeffs = [1, -5, 8, -4, 0, 0]\n",
    "predicted_roots, real_parts, imag_parts = predict_polynomial_roots(sample_coeffs)\n",
    "\n",
    "print(f\"Input polynomial coefficients: {sample_coeffs}\")\n",
    "print(f\"Predicted roots:\")\n",
    "for i, root in enumerate(predicted_roots):\n",
    "    print(f\"  Root {i+1}: {root:.4f}\")\n",
    "\n",
    "# Save model components\n",
    "# joblib.dump(scaler_X, 'scaler_X.pkl')\n",
    "# joblib.dump(scaler_y, 'scaler_y.pkl')\n",
    "\n",
    "print(\"Model and scalers saved successfully!\")\n",
    "print(\"\\nTo use the trained model in a new session:\")\n",
    "print(\"1. model = keras.models.load_model('best_polynomial_roots_model.keras')\")\n",
    "print(\"2. scaler_X = joblib.load('scaler_X.pkl')\")\n",
    "print(\"3. scaler_y = joblib.load('scaler_y.pkl')\")\n",
    "\n",
    "# Additional utility functions for comprehensive usage\n",
    "def load_trained_model():\n",
    "    \"\"\"Load the trained model and scalers for inference\"\"\"\n",
    "    model = keras.models.load_model('best_polynomial_roots_model.keras')\n",
    "    # scaler_X = joblib.load('scaler_X.pkl')\n",
    "    # scaler_y = joblib.load('scaler_y.pkl')\n",
    "    return model#, scaler_X, scaler_y\n",
    "\n",
    "def batch_predict_roots(coefficient_list):\n",
    "    \"\"\"Predict roots for multiple polynomials at once\"\"\"\n",
    "    coeffs_array = np.array(coefficient_list)\n",
    "    # coeffs_scaled = scaler_X.transform(coeffs_array)\n",
    "    \n",
    "    predictions_scaled = model.predict(coeffs_array, verbose=0)\n",
    "    # predictions = scaler_y.inverse_transform(predictions_scaled)\n",
    "    \n",
    "    results = []\n",
    "    for i, prediction in enumerate(predictions_scaled):\n",
    "        real_parts = prediction[:5]\n",
    "        imag_parts = prediction[5:]\n",
    "        roots = real_parts + 1j * imag_parts\n",
    "        results.append({\n",
    "            'coefficients': coefficient_list[i],\n",
    "            'roots': roots,\n",
    "            'real_parts': real_parts,\n",
    "            'imaginary_parts': imag_parts\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def verify_polynomial_roots(coeffs, roots, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Verify that the predicted roots actually satisfy the polynomial equation\n",
    "    \"\"\"\n",
    "    a, b, c, d, e, f = coeffs\n",
    "    verification_results = []\n",
    "    \n",
    "    for i, root in enumerate(roots):\n",
    "        # Calculate polynomial value at root\n",
    "        poly_value = a*root**5 + b*root**4 + c*root**3 + d*root**2 + e*root + f\n",
    "        error = abs(poly_value)\n",
    "        is_valid = error < tolerance\n",
    "        \n",
    "        verification_results.append({\n",
    "            'root_index': i+1,\n",
    "            'root_value': root,\n",
    "            'polynomial_value': poly_value,\n",
    "            'error': error,\n",
    "            'is_valid_root': is_valid\n",
    "        })\n",
    "    \n",
    "    return verification_results\n",
    "\n",
    "# Example usage for batch prediction\n",
    "sample_batch = [\n",
    "    [1, -5, 8, -4, 0, 0],\n",
    "    [10, 20, -31, 0, 11, -2],\n",
    "    [12, -51, 82, -4, 2, 2],\n",
    "    [-2, 1, -3, 4, 1, -2],\n",
    "    [1, -5, 8, -4, 0, 0],\n",
    "    [2, 1, -3, 0, 1, -2],\n",
    "    [1, -5, 8, -4, 0, 0],\n",
    "    [2, 1, -3, 0, 1, -2],\n",
    "    [1, 0, 0, 0, 0, -1]\n",
    "]\n",
    "\n",
    "batch_results = batch_predict_roots(sample_batch)\n",
    "print(\"\\nBatch prediction results:\")\n",
    "for i, result in enumerate(batch_results):\n",
    "    print(f\"Polynomial {i+1}: {result['coefficients']}\")\n",
    "    print(f\"Roots: {result['roots']}\")\n",
    "    \n",
    "    # Verify the roots\n",
    "    verification = verify_polynomial_roots(result['coefficients'], result['roots'])\n",
    "    print(\"Root verification:\")\n",
    "    for v in verification:\n",
    "        status = \"✓\" if v['is_valid_root'] else \"✗\"\n",
    "        print(f\"  {status} Root {v['root_index']}: Error = {v['error']:.2e}\")\n",
    "    print()\n",
    "\n",
    "print(\"Code execution completed successfully!\")\n",
    "\n",
    "# The errors in deep NN for the function approximation are 0.02 to 2 while predicting the roots ,\n",
    "# implying that either the architecture needs update or data of the coefficients should be more and\n",
    "# may include decimal coefficients instead of just integer coefficients as in the data..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
